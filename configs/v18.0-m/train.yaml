model: ./model.yaml

optimizer:
  name: AdamW
  kwargs:
    lr: 1  # Will be multiplied by scheduler
    weight_decay: 0.01
    betas: [0.9, 0.95]

lr_scheduler:
  name: Trapezoidal
  kwargs:
    min_lr: 0
    max_lr: 1e-4
    warmup_steps: 500_000
    annealing_steps: 1_000_000
    total_steps: 5_000_000

batch_size: 128

train_dataset: ./dataset_train.yaml
val_dataset: "./dataset_val.yaml"
val_batch_size: 128
val_size: 100_000

compile_mode: 'reduce-overhead'
gradient_checkpointing: False

wandb_watch_log: null
wandb_watch_log_freq: 1000

steps: 5_000_000
device: cuda