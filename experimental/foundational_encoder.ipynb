{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from flash_ansr.models import SetTransformer, PreEncoder\n",
    "from flash_ansr import get_path, FlashANSRDataset, ExpressionSpace\n",
    "from flash_ansr.train.loss import ContrastiveLoss\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_VARIABLES = 11\n",
    "OUTPUT_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_encoder = PreEncoder(\n",
    "    input_size=N_VARIABLES + 1,\n",
    "    mode=\"ieee-754\",\n",
    "    support_nan=False,\n",
    "    exponent_scale=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"hidden_size\": 512,\n",
    "    \"n_enc_isab\": 5,\n",
    "    \"n_dec_sab\": 2,\n",
    "    \"n_induce\": 64,\n",
    "    \"n_heads\": 8,\n",
    "    \"layer_norm\": False,\n",
    "    \"n_seeds\": 64,\n",
    "    \"input_embedding_size\": pre_encoder.encoding_size,\n",
    "    \"input_dimension_size\": pre_encoder.input_size,\n",
    "    \"output_embedding_size\": OUTPUT_SIZE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13,625,856\n"
     ]
    }
   ],
   "source": [
    "print(f'{SetTransformer(**model_config).n_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetTransformerWrapper(nn.Module):\n",
    "    def __init__(self, expression_space: ExpressionSpace, set_transformer: SetTransformer, pre_encoder: PreEncoder):\n",
    "        super().__init__()\n",
    "        self.expression_space = expression_space\n",
    "        self.pre_encoder = pre_encoder\n",
    "        self.set_transformer = set_transformer\n",
    "        set_transformer_output_size = set_transformer.output_embedding_size * set_transformer.n_seeds\n",
    "        self.token_head = nn.Linear(set_transformer_output_size, len(expression_space.tokenizer.vocab))\n",
    "        self.complexity_head = nn.Linear(set_transformer_output_size, 1)\n",
    "        self.n_constants_head = nn.Linear(set_transformer_output_size, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        B, M, D = x.size()\n",
    "        data_pre_encodings = self.pre_encoder(x)\n",
    "        data_pre_encodings = data_pre_encodings.view(B, M, D, self.pre_encoder.encoding_size)\n",
    "        x = self.set_transformer(data_pre_encodings)\n",
    "        B, S, D = x.size()\n",
    "        x = x.view(B, S * D)\n",
    "        token_logits = self.token_head(x)\n",
    "        complexity = self.complexity_head(x)\n",
    "        n_constants = self.n_constants_head(x)\n",
    "        return token_logits, complexity, n_constants\n",
    "    \n",
    "    @property\n",
    "    def n_params(self):\n",
    "        return sum(p.numel() for p in self.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling Skeletons: 100%|██████████| 200/200 [00:00<00:00, 48839.12it/s]\n",
      "Compiling Skeletons: 100%|██████████| 43/43 [00:00<00:00, 37985.48it/s]\n",
      "Compiling Skeletons: 100%|██████████| 10/10 [00:00<00:00, 29066.56it/s]\n",
      "Compiling Skeletons: 100%|██████████| 4999/4999 [00:00<00:00, 30367.23it/s]\n",
      "Compiling Skeletons: 100%|██████████| 5000/5000 [00:00<00:00, 39489.70it/s]\n",
      "Compiling Skeletons: 100%|██████████| 200/200 [00:00<00:00, 53220.45it/s]\n",
      "Compiling Skeletons: 100%|██████████| 43/43 [00:00<00:00, 45201.77it/s]\n",
      "Compiling Skeletons: 100%|██████████| 10/10 [00:00<00:00, 28591.03it/s]\n",
      "Compiling Skeletons: 100%|██████████| 4999/4999 [00:00<00:00, 30463.01it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_train = FlashANSRDataset.from_config(get_path(\"configs\", \"v7.0\", \"dataset_train.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling Skeletons: 100%|██████████| 200/200 [00:00<00:00, 53261.00it/s]\n",
      "Compiling Skeletons: 100%|██████████| 43/43 [00:00<00:00, 42416.53it/s]\n",
      "Compiling Skeletons: 100%|██████████| 10/10 [00:00<00:00, 30218.33it/s]\n",
      "Compiling Skeletons: 100%|██████████| 4999/4999 [00:00<00:00, 29678.92it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_val = FlashANSRDataset.from_config(get_path(\"configs\", \"v7.0\", \"dataset_val.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_targets(batch: dict, device: torch.device) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    # Complexity targets by counting the number of non-padding tokens in each instance\n",
    "    complexity_targets = (batch[\"input_ids\"] != 0).sum(dim=1).unsqueeze(1).float() - 2  # Subtract 2 to account for the start and end tokens\n",
    "\n",
    "    # Number of constants targets by counting the number of '<num>' tokens in each instance\n",
    "    n_constants_targets = (batch[\"input_ids\"] == dataset_train.expression_space.tokenizer[\"<num>\"]).sum(dim=1).unsqueeze(1).float()\n",
    "\n",
    "    # Binary token targets that depict for each token in the vocabulary whether it is present in the instance\n",
    "    token_targets = torch.zeros(batch[\"input_ids\"].shape[0], len(dataset_train.expression_space.tokenizer.vocab), device=device)\n",
    "    for i, tokens in enumerate(batch[\"input_ids\"]):\n",
    "        token_targets[i, tokens] = 1\n",
    "\n",
    "    return token_targets, complexity_targets, n_constants_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpsaegert\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/psaegert/Projects/flash-ansr/experimental/wandb/run-20250329_141940-0fuyyj1a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/psaegert/foundation_set_encoder/runs/0fuyyj1a' target=\"_blank\">set-transformer-combined</a></strong> to <a href='https://wandb.ai/psaegert/foundation_set_encoder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/psaegert/foundation_set_encoder' target=\"_blank\">https://wandb.ai/psaegert/foundation_set_encoder</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/psaegert/foundation_set_encoder/runs/0fuyyj1a' target=\"_blank\">https://wandb.ai/psaegert/foundation_set_encoder/runs/0fuyyj1a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 35999/1000000 [2:40:39<71:42:00,  3.73it/s]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_20585/1588366544.py\", line 75, in <module>\n",
      "    for val_batch in dataset_val.iterate(steps=train_config['val_steps'], batch_size=train_config[\"batch_size\"], n_per_equation=train_config[\"n_per_equation\"]):\n",
      "  File \"/home/psaegert/Projects/flash-ansr/src/flash_ansr/data.py\", line 315, in iterate\n",
      "    yield from self.generate_batch(batch_size=batch_size, size=size, steps=steps, n_support=n_support, n_per_equation=n_per_equation, tqdm_total=tqdm_total, verbose=verbose, avoid_fragmentation=avoid_fragmentation)\n",
      "  File \"/home/psaegert/Projects/flash-ansr/src/flash_ansr/data.py\", line 393, in generate_batch\n",
      "    for instance in self.generate(\n",
      "  File \"/home/psaegert/Projects/flash-ansr/src/flash_ansr/data.py\", line 458, in generate\n",
      "    skeleton_hash, skeleton_code, skeleton_constants = self.skeleton_pool.sample_skeleton()\n",
      "                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/psaegert/Projects/flash-ansr/src/flash_ansr/expressions/skeleton_pool.py\", line 542, in sample_skeleton\n",
      "    skeleton = self._sample_skeleton(n_operators)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/psaegert/Projects/flash-ansr/src/flash_ansr/expressions/skeleton_pool.py\", line 476, in _sample_skeleton\n",
      "    skipped, arity = self.sample_next_pos_ubi(n_empty_nodes, n)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/psaegert/Projects/flash-ansr/src/flash_ansr/expressions/skeleton_pool.py\", line 408, in sample_next_pos_ubi\n",
      "    def sample_next_pos_ubi(self, n_empty_nodes: int, n_operators: int) -> tuple[int, int]:\n",
      "    \n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6a7839bb8e470ca3ff8cc36f180bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.007 MB of 0.007 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>cumulative_flops</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>train_complexity_loss</td><td>█▄▂▂▃▂▄▂▂▂▃▂▃▂▃▃▂▃▁▂▃▁▃▁▃▁▄▅▁▃▄▃▂▁▃▁▂▁▂▂</td></tr><tr><td>train_loss</td><td>▆▇▄▃▄▃▃▃▂▇▄▇▄▄▄▃▂▆▅▃█▄▆▁▃▂▄▂▄▇▃▂▃▄▃▄▆▄▃▄</td></tr><tr><td>train_n_constants_loss</td><td>▅▄▃▃▄▇▃█▅▇▂▄▇▆▇▃▇▃▃▅▆█▂▃▃▃▆▄▄▁▅▁▄▃▄▄▃▃▄▅</td></tr><tr><td>train_token_loss</td><td>█▅▅▅▇▄▄▄▄▂▃▃▅▄▄▄▂▃▁▅▂▁▁▂▂▂▃▄▄▅▄▄▅▃▂▁▃▃▄▃</td></tr><tr><td>val_complexity_loss</td><td>█▃▄▄▇▅▅▃▃▃▂▃▃▃▃▂▂▂▂▂▄▂▁▃▂▂▂▃▃▃▁▂▂▁▂</td></tr><tr><td>val_contrastive_loss</td><td>█▃▄▄▇▅▅▄▃▃▃▃▃▃▃▂▂▂▂▂▄▂▁▃▂▂▂▃▃▃▁▂▂▁▂</td></tr><tr><td>val_n_constants_loss</td><td>▇█▆█▆▅▆▇▅▅▆▄█▄▄█▃▄▄▄▅▄▁▄▃▂▄▃▃▄▁▂▄▂▃</td></tr><tr><td>val_token_loss</td><td>█▅▆▄▆▄▄▄▃▃▃▂▂▂▂▂▂▃▃▁▂▂▂▁▁▁▂▁▂▁▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>cumulative_flops</td><td>107.52222</td></tr><tr><td>train_complexity_loss</td><td>10.14577</td></tr><tr><td>train_loss</td><td>11.1266</td></tr><tr><td>train_n_constants_loss</td><td>0.76068</td></tr><tr><td>train_token_loss</td><td>0.22014</td></tr><tr><td>val_complexity_loss</td><td>10.53826</td></tr><tr><td>val_contrastive_loss</td><td>11.70493</td></tr><tr><td>val_n_constants_loss</td><td>0.94174</td></tr><tr><td>val_token_loss</td><td>0.22493</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">set-transformer-combined</strong> at: <a href='https://wandb.ai/psaegert/foundation_set_encoder/runs/0fuyyj1a' target=\"_blank\">https://wandb.ai/psaegert/foundation_set_encoder/runs/0fuyyj1a</a><br/> View project at: <a href='https://wandb.ai/psaegert/foundation_set_encoder' target=\"_blank\">https://wandb.ai/psaegert/foundation_set_encoder</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250329_141940-0fuyyj1a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrupted training. Attempting to save model.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SetTransformerWrapper' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 117\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted training. Attempting to save model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m model\u001b[38;5;241m.\u001b[39msave(get_path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mansr-models\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_transformer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv7.0\u001b[39m\u001b[38;5;124m\"\u001b[39m, create\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m~/miniconda3/envs/flash-ansr/lib/python3.11/site-packages/torch/nn/modules/module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1933\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SetTransformerWrapper' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "train_config = {\n",
    "    \"n_per_equation\": 1,\n",
    "    \"batch_size\": 128,\n",
    "    \"steps\": 1_000_000,\n",
    "    \"val_steps\": 100,\n",
    "    \"val_every_steps\": 1_000,\n",
    "    \"lr\": 1e-4,\n",
    "}\n",
    "\n",
    "loss_fn_token = nn.BCEWithLogitsLoss()\n",
    "loss_fn_complexity = nn.MSELoss()\n",
    "loss_fn_n_constants = nn.MSELoss()\n",
    "\n",
    "model = SetTransformerWrapper(\n",
    "    set_transformer=SetTransformer(**model_config),\n",
    "    expression_space=dataset_train.expression_space,\n",
    "    pre_encoder=pre_encoder).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=train_config['lr'], amsgrad=True)\n",
    "n_params = model.n_params\n",
    "flops_per_token = 6 * n_params\n",
    "\n",
    "cumulative_training_pflops = 0\n",
    "\n",
    "try:\n",
    "    with wandb.init(config=train_config | model_config, project=\"foundation_set_encoder\", entity=\"psaegert\", name=f'set-transformer-combined'):\n",
    "        pbar = tqdm(total=train_config['steps'], smoothing=0)\n",
    "        model.train()\n",
    "        for b, batch in enumerate(dataset_train.iterate(steps=train_config['steps'], batch_size=train_config['batch_size'], n_per_equation=train_config['n_per_equation'])):\n",
    "            optimizer.zero_grad()\n",
    "            batch = dataset_train.collate(batch, device)\n",
    "\n",
    "            # Pad the x_tensor with zeros to match the expected maximum input dimension of the set transformer\n",
    "            pad_length = N_VARIABLES - batch[\"x_tensors\"].shape[2]\n",
    "            if pad_length > 0:\n",
    "                x_tensor = nn.functional.pad(batch[\"x_tensors\"], (0, pad_length, 0, 0, 0, 0), value=0)\n",
    "            else:\n",
    "                x_tensor = batch[\"x_tensors\"]\n",
    "\n",
    "            # Concatenate x and y tensors as input to the set transformer\n",
    "            data_tensor = torch.cat([x_tensor, batch[\"y_tensors\"]], dim=-1)\n",
    "\n",
    "            # Targets\n",
    "            token_targets, complexity_targets, n_constants_targets = create_targets(batch, device)\n",
    "\n",
    "            # Forward pass\n",
    "            logits, complexity, n_const = model(data_tensor)\n",
    "            \n",
    "            loss_token: torch.Tensor = loss_fn_token(logits, token_targets)\n",
    "            loss_complexity: torch.Tensor = loss_fn_complexity(complexity, complexity_targets)\n",
    "            loss_n_constants: torch.Tensor = loss_fn_n_constants(n_const, n_constants_targets)\n",
    "\n",
    "            loss: torch.Tensor = loss_token + loss_complexity + loss_n_constants\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            cumulative_training_pflops += (flops_per_token * batch[\"x_tensors\"].shape[0] * batch[\"x_tensors\"].shape[1]) * 1e-15\n",
    "\n",
    "            wandb.log({\n",
    "                \"train_loss\": loss.item(),\n",
    "                \"train_token_loss\": loss_token.item(),\n",
    "                \"train_complexity_loss\": loss_complexity.item(),\n",
    "                \"train_n_constants_loss\": loss_n_constants.item(),\n",
    "                \"cumulative_flops\": cumulative_training_pflops,\n",
    "            }, step=b)\n",
    "\n",
    "            if (b + 1) % train_config[\"val_every_steps\"] == 0:\n",
    "                model.eval()\n",
    "                val_losses = []\n",
    "                val_token_losses = []\n",
    "                val_complexity_losses = []\n",
    "                val_n_constants_losses = []\n",
    "                with torch.no_grad():\n",
    "                    for val_batch in dataset_val.iterate(steps=train_config['val_steps'], batch_size=train_config[\"batch_size\"], n_per_equation=train_config[\"n_per_equation\"]):\n",
    "                        val_batch = dataset_val.collate(val_batch, device)\n",
    "\n",
    "                        pad_length = N_VARIABLES - val_batch[\"x_tensors\"].shape[2]\n",
    "                        if pad_length > 0:\n",
    "                            x_tensor = nn.functional.pad(val_batch[\"x_tensors\"], (0, pad_length, 0, 0, 0, 0), value=0)\n",
    "                        else:\n",
    "                            x_tensor = val_batch[\"x_tensors\"]\n",
    "\n",
    "                        data_tensor = torch.cat([x_tensor, val_batch[\"y_tensors\"]], dim=-1)\n",
    "                        \n",
    "                        token_targets, complexity_targets, n_constants_targets = create_targets(val_batch, device)\n",
    "\n",
    "                        logits, complexity, n_const = model(data_tensor)\n",
    "\n",
    "                        loss_token: torch.Tensor = loss_fn_token(logits, token_targets)\n",
    "                        loss_complexity: torch.Tensor = loss_fn_complexity(complexity, complexity_targets)\n",
    "                        loss_n_constants: torch.Tensor = loss_fn_n_constants(n_const, n_constants_targets)\n",
    "\n",
    "                        loss: torch.Tensor = loss_token + loss_complexity + loss_n_constants\n",
    "\n",
    "                        val_losses.append(loss.item())\n",
    "                        val_token_losses.append(loss_token.item())\n",
    "                        val_complexity_losses.append(loss_complexity.item())\n",
    "                        val_n_constants_losses.append(loss_n_constants.item())\n",
    "\n",
    "                wandb.log({\n",
    "                    \"val_loss\": np.mean(val_losses),\n",
    "                    \"val_token_loss\": np.mean(val_token_losses),\n",
    "                    \"val_complexity_loss\": np.mean(val_complexity_losses),\n",
    "                    \"val_n_constants_loss\": np.mean(val_n_constants_losses),\n",
    "                    }, step=b)\n",
    "\n",
    "                model.train()\n",
    "    \n",
    "            pbar.update()\n",
    "\n",
    "        pbar.close()\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted training. Attempting to save model.\")\n",
    "\n",
    "model.save(get_path(\"models\", \"ansr-models\", \"set_transformer\", f\"v7.0\", create=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b, batch in enumerate(dataset_train.iterate(steps=train_config['steps'], batch_size=train_config['batch_size'], n_per_equation=train_config['n_per_equation'])):\n",
    "    batch = dataset_train.collate(batch, device)\n",
    "    target_tokens, target_complexity, target_n_constants = create_targets(batch, device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, complexity, n_constants = model(data_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 10, 12, 15, 30,  8, 12, 11, 24, 31,  6,  6,  2,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0], device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -4.1\n",
      "1 -0.3\n",
      "2 -0.3\n",
      "3 -12.7\n",
      "4 -12.7\n",
      "5 -12.7\n",
      "6 -6.2\n",
      "7 -6.2\n",
      "8 -6.7\n",
      "9 -7.4\n",
      "10 -5.8\n",
      "11 -6.3\n",
      "12 -7.2\n",
      "13 -7.3\n",
      "14 -6.5\n",
      "15 -7.0\n",
      "16 -7.0\n",
      "17 -7.1\n",
      "18 -8.6\n",
      "19 -8.9\n",
      "20 -9.1\n",
      "21 -9.2\n",
      "22 -7.5\n",
      "23 -7.6\n",
      "24 -7.5\n",
      "25 -8.9\n",
      "26 -9.1\n",
      "27 -7.7\n",
      "28 -6.7\n",
      "29 -8.5\n",
      "30 -3.3\n",
      "31 -3.1\n",
      "32 -8.9\n"
     ]
    }
   ],
   "source": [
    "for i, logit in enumerate(torch.softmax(logits[1], dim=-1)):\n",
    "    print(f'{i} {logit.log10().item():.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0 12.875956535339355\n",
      "11.0 10.489505767822266\n",
      "6.0 14.327173233032227\n",
      "14.0 14.180545806884766\n",
      "10.0 14.659640312194824\n"
     ]
    }
   ],
   "source": [
    "for target_complexity_item, predicted_complexity in zip(target_complexity[:5], complexity):\n",
    "    print(f'{target_complexity_item.item()} {predicted_complexity.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.1526859998703003\n",
      "2.0 0.9796116948127747\n",
      "0.0 1.2337887287139893\n",
      "2.0 0.9209513664245605\n",
      "1.0 1.6110610961914062\n"
     ]
    }
   ],
   "source": [
    "for target_n_constants_item, predicted_n_constants in zip(target_n_constants[:5], n_constants):\n",
    "    print(f'{target_n_constants_item.item()} {predicted_n_constants.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flash-ansr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
