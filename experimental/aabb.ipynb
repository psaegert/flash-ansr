{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from flash_ansr.models.encoders import SAB, MAB\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(111, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.4810, -2.4991, -2.8691])\n",
      "tensor([2.0126, 2.4688, 2.2511])\n",
      "tensor([4.4936, 4.9679, 5.1202])\n"
     ]
    }
   ],
   "source": [
    "mins = X.min(dim=0).values\n",
    "maxs = X.max(dim=0).values\n",
    "ranges = maxs - mins\n",
    "print(mins)\n",
    "print(maxs)\n",
    "print(ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_mask(X: torch.Tensor) -> torch.Tensor:\n",
    "    mins = X.min(dim=0).values\n",
    "    maxs = X.max(dim=0).values\n",
    "    ranges = maxs - mins\n",
    "    max_range_dim = ranges.argmax()\n",
    "    \n",
    "    split_value = torch.median(X[:, max_range_dim])\n",
    "    # print(f\"Splitting {X.shape=} on dimension {max_range_dim} at value {split_value}\")\n",
    "\n",
    "    return X[:, max_range_dim] < split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False,  True, False,  True,  True, False, False, False,  True,\n",
       "         True,  True,  True,  True, False, False, False, False,  True,  True,\n",
       "         True, False, False,  True, False, False, False, False, False, False,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True, False,\n",
       "         True,  True, False,  True, False, False, False,  True,  True, False,\n",
       "        False,  True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "         True, False, False,  True,  True,  True, False, False, False, False,\n",
       "        False,  True, False, False, False,  True,  True,  True,  True,  True,\n",
       "        False, False, False, False, False, False,  True, False,  True, False,\n",
       "        False, False, False, False, False, False, False,  True,  True,  True,\n",
       "        False])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_mask(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(128, 111, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_mask_batched(X: torch.Tensor) -> torch.Tensor:\n",
    "    if X.ndim != 3:\n",
    "        raise ValueError(f\"Expected 3D tensor, got {X.ndim}D tensor of shape {X.shape}\")\n",
    "\n",
    "    mins = X.min(dim=1).values\n",
    "    maxs = X.max(dim=1).values\n",
    "    ranges = maxs - mins\n",
    "    max_range_dim = ranges.argmax(dim=1)\n",
    "\n",
    "    split_value = torch.median(X[np.arange(X.shape[0]), :, max_range_dim], dim=1).values\n",
    "\n",
    "    return X[np.arange(X.shape[0]), :, max_range_dim] < split_value.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_mask_batched(X: torch.Tensor) -> torch.Tensor:\n",
    "    if X.ndim != 3:\n",
    "        raise ValueError(f\"Expected 3D tensor, got {X.ndim}D tensor of shape {X.shape}\")\n",
    "\n",
    "    batch_size, num_points, _ = X.shape\n",
    "\n",
    "    # Find dimension with max range for each batch\n",
    "    mins = X.min(dim=1).values\n",
    "    maxs = X.max(dim=1).values\n",
    "    ranges = maxs - mins\n",
    "    max_range_dim = ranges.argmax(dim=1)\n",
    "\n",
    "    # Initialize result mask\n",
    "    result_mask = torch.zeros((batch_size, num_points), dtype=torch.bool, device=X.device)\n",
    "\n",
    "    # Process each batch independently\n",
    "    for i in range(batch_size):\n",
    "        # Extract values along the max range dimension for this batch\n",
    "        values = X[i, :, max_range_dim[i]]\n",
    "\n",
    "        # Calculate target size for the first half\n",
    "        target_size = num_points // 2\n",
    "\n",
    "        # Find median value (equivalent to finding kth element)\n",
    "        median_value = torch.kthvalue(values, target_size + 1).values\n",
    "\n",
    "        # Create masks for each category\n",
    "        less_mask = values < median_value\n",
    "        equal_mask = values == median_value\n",
    "\n",
    "        # Count elements in each category\n",
    "        less_count = torch.sum(less_mask).item()\n",
    "        equal_count = torch.sum(equal_mask).item()\n",
    "\n",
    "        # Calculate how many median elements go to first half to maintain balance\n",
    "        median_in_first = max(0, target_size - less_count)\n",
    "\n",
    "        # If we need to split the median elements\n",
    "        if 0 < median_in_first < equal_count:\n",
    "            # Get indices of the median elements\n",
    "            equal_indices = torch.nonzero(equal_mask, as_tuple=True)[0]\n",
    "\n",
    "            # Add the required number of median elements to the less mask\n",
    "            result_mask[i, less_mask] = True\n",
    "            result_mask[i, equal_indices[:median_in_first]] = True\n",
    "        else:\n",
    "            # Simple case: all less than median, and possibly some equal to median\n",
    "            result_mask[i] = values <= median_value if less_count < target_size else less_mask\n",
    "\n",
    "    return result_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 111])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = split_mask_batched(X)\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7040, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.99 ms ± 186 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "X = torch.randn(128, 512, 3)\n",
    "mask = split_mask_batched(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.8 ms ± 2.08 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "X = torch.randn(128, 512, 3, device=device)\n",
    "mask = split_mask_batched(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, X: torch.Tensor, left=None, right=None):\n",
    "        self.X = X\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_tree(X: torch.Tensor, max_depth: int = 5, min_n_leaf: int | None = None, depth: int = 0) -> torch.Tensor:\n",
    "#     if min_n_leaf is None:\n",
    "#         min_n_leaf = np.sqrt(X.shape[0])\n",
    "\n",
    "#     if depth + 1 >= max_depth or X.shape[0] <= min_n_leaf:\n",
    "#         return Node(X)\n",
    "\n",
    "#     mask = split_mask(X)\n",
    "\n",
    "#     return Node(X, create_tree(X[mask], max_depth, min_n_leaf, depth + 1), create_tree(X[~mask], max_depth, min_n_leaf, depth + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(X: torch.Tensor, max_depth: int = 5, depth: int = 0) -> torch.Tensor:\n",
    "    if depth + 1 >= max_depth:\n",
    "        return Node(X)\n",
    "\n",
    "    if X.shape[0] > 1:\n",
    "        mask = split_mask(X)\n",
    "        return Node(X, create_tree(X[mask], max_depth, depth + 1), create_tree(X[~mask], max_depth, depth + 1))\n",
    "    \n",
    "    return Node(X, create_tree(X, max_depth, depth + 1), create_tree(X, max_depth, depth + 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(512, 3)\n",
    "tree = create_tree(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(4, 3)\n",
    "tree = create_tree(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(152, 3)\n",
    "tree = create_tree(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# X = torch.randn(512, 3)\n",
    "# tree = create_tree(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can make this batched!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree_batched(X: torch.Tensor, max_depth: int = 5, depth: int = 0) -> torch.Tensor:\n",
    "    if X.ndim != 3:\n",
    "        raise ValueError(f\"Expected 3D tensor, got {X.ndim}D tensor of shape {X.shape}\")\n",
    "\n",
    "    if depth + 1 >= max_depth:\n",
    "        return Node(X)\n",
    "\n",
    "    if X.shape[1] > 1:\n",
    "        mask_batched = split_mask_batched(X)\n",
    "        X_left = torch.stack([X[i][mask_batched[i]] for i in range(X.shape[0])], dim=0)\n",
    "        X_right = torch.stack([X[i][~mask_batched[i]] for i in range(X.shape[0])], dim=0)    \n",
    "        # print(X_left.shape)\n",
    "        # print(X_right.shape)    \n",
    "        return Node(X, create_tree_batched(X_left, max_depth, depth + 1), create_tree_batched(X_right, max_depth, depth + 1))\n",
    "    \n",
    "    return Node(X, create_tree_batched(X, max_depth, depth + 1), create_tree_batched(X, max_depth, depth + 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(128, 111, 3)\n",
    "tree_batched = create_tree_batched(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(128, 152, 4)\n",
    "tree_batched = create_tree_batched(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.6 ms ± 925 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "X = torch.randn(128, 512, 3)\n",
    "tree_batched = create_tree_batched(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432 ms ± 48 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "X = torch.randn(128, 512, 3, device=device)\n",
    "tree_batched = create_tree_batched(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 13, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_batched.left.left.left.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeSetEncoder(nn.Module):\n",
    "    def __init__(self, depth: int, features_in: int, features_hidden: int = 512, n_heads: int = 8, clean_path: bool = True):\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.features_in = features_in\n",
    "        self.features_hidden = features_hidden\n",
    "\n",
    "        self.linear_in = nn.Linear(features_in, features_hidden)\n",
    "\n",
    "        self.sabs = nn.ModuleList([SAB(features_hidden, n_heads=n_heads, clean_path=clean_path) for _ in range(depth)])\n",
    "        self.mabs_lr = nn.ModuleList([MAB(features_hidden,n_heads=n_heads, clean_path=clean_path) for _ in range(depth)])\n",
    "        self.mabs_rl = nn.ModuleList([MAB(features_hidden, n_heads=n_heads, clean_path=clean_path) for _ in range(depth)])\n",
    "\n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        if X.ndim > 3:\n",
    "            raise ValueError(f\"Expected 2D or 3D tensor, got {X.ndim}D tensor of shape {X.shape}\")\n",
    "        elif X.ndim == 2:\n",
    "            X = X.unsqueeze(0)\n",
    "        elif X.ndim != 3:\n",
    "            raise ValueError(f\"Expected 2D or 3D tensor, got {X.ndim}D tensor of shape {X.shape}\")\n",
    "\n",
    "        tree_batched = create_tree_batched(X.cpu(), max_depth=self.depth)\n",
    "        return self.encode_tree(tree_batched)\n",
    "\n",
    "    def encode_tree(self, tree: Node, depth: int = 0) -> list[tuple[int, int]]:\n",
    "        if tree.left is None and tree.right is None:\n",
    "            # Leaf node\n",
    "            return self.linear_in(tree.X.to(device))\n",
    "\n",
    "        X_left = self.encode_tree(tree.left, depth + 1)\n",
    "        X_right = self.encode_tree(tree.right, depth + 1)\n",
    "\n",
    "        X_left = self.sabs[depth](X_left)\n",
    "        X_right = self.sabs[depth](X_right)\n",
    "\n",
    "        X_lr = self.mabs_lr[depth](X_left, X_right)\n",
    "\n",
    "        X_lr_rl = self.mabs_rl[depth](X_right, X_lr)\n",
    "\n",
    "        return X_lr_rl\n",
    "    \n",
    "    @property\n",
    "    def n_params(self) -> int:\n",
    "        return sum(p.numel() for p in self.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15,761,408 params\n"
     ]
    }
   ],
   "source": [
    "encoder = TreeSetEncoder(depth=5, features_in=3).to(device)\n",
    "print(f'{encoder.n_params:,} params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.8 ms ± 3.94 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "X = torch.randn(128, 512, 3, device=device)\n",
    "z = encoder.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.3 ms ± 1.69 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "X = torch.randn(128, 512, 3, device=device)\n",
    "with torch.no_grad():\n",
    "    z = encoder.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 33, 512])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(128, 512, 3, device=device)\n",
    "z = encoder.forward(X.to(device))\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 9, 512])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(128, 128, 3, device=device)\n",
    "z = encoder.forward(X.to(device))\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 2, 512])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(128, 10, 3, device=device)\n",
    "z = encoder.forward(X.to(device))\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(128, 1, 3, device=device)\n",
    "z = encoder.forward(X.to(device))\n",
    "z.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flash-ansr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
