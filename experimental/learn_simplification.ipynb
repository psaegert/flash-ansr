{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flash_ansr.expressions import ExpressionSpace\n",
    "from flash_ansr.expressions.utils import codify, num_to_constants\n",
    "from flash_ansr import get_path\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from typing import Generator, Callable\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'v7.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_path('configs', MODEL, 'expression_space.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = ExpressionSpace.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x1', 'x2', 'x3', '<num>']\n",
      "{'neg': 1, 'abs': 1, 'inv': 1, 'pow2': 1, 'pow3': 1, 'pow4': 1, 'pow5': 1, 'pow1_2': 1, 'pow1_3': 1, 'pow1_4': 1, 'pow1_5': 1, 'sin': 1, 'cos': 1, 'tan': 1, 'asin': 1, 'acos': 1, 'atan': 1, 'exp': 1, 'log': 1, '+': 2, '-': 2, '*': 2, '/': 2}\n"
     ]
    }
   ],
   "source": [
    "leaf_nodes = space.variables + [\"<num>\"]\n",
    "non_leaf_nodes = space.operator_arity\n",
    "non_leaf_nodes = dict(sorted(non_leaf_nodes.items(), key=lambda x: x[1]))\n",
    "\n",
    "print(leaf_nodes)\n",
    "print(non_leaf_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['+', 'cos', 'x', 'sin', '*', 'pow2', 'x', 'pow2', 'x']\n"
     ]
    }
   ],
   "source": [
    "def apply_rule(X, A, B):\n",
    "    result = []\n",
    "    i = 0\n",
    "    while i < len(X):\n",
    "        # Check if sublist A is found at current position\n",
    "        if i <= len(X) - len(A) and X[i:i+len(A)] == A:\n",
    "            # Add replacement sublist B\n",
    "            result.extend(B)\n",
    "            # Skip past the matched sublist A\n",
    "            i += len(A)\n",
    "        else:\n",
    "            # Add current element and move to next\n",
    "            result.append(X[i])\n",
    "            i += 1\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "X = ['+', 'cos', 'x', 'sin', '*', '*', 'x', 'x', '*', 'x', 'x']\n",
    "A = ['*', 'x', 'x']\n",
    "B = ['pow2', 'x']\n",
    "print(apply_rule(X, A, B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify(expression: list[str], rules: set[tuple[list[str], list[str]]]):\n",
    "    if isinstance(expression, tuple):\n",
    "        expression = list(expression)\n",
    "    for pattern, replacement in rules:\n",
    "        expression = apply_rule(expression, pattern, replacement)\n",
    "    return expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['+', 'cos', 'x', 'sin', '*', 'pow2', 'x', 'pow2', 'x']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplify(['+', 'cos', 'x', 'sin', '*', '*', 'x', 'x', '*', 'x', 'x'], [(['*', 'x', 'x'], ['pow2', 'x'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', '0']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplify(['neg', '-', 'x1', 'x1'], [(['-', 'x1', 'x1'], ['0'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<num>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplify(['<num>'], rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expression_generator(hashes_of_size: dict[int, list[tuple[str]]], non_leaf_nodes: dict[str, int]) -> Generator[tuple[str], None, None]:\n",
    "    # Append existing trees to every operator\n",
    "    for new_root_operator, arity in non_leaf_nodes.items():\n",
    "        # Start with the smallest arity-tuples of trees\n",
    "        for child_lengths in sorted(itertools.product(list(hashes_of_size.keys()), repeat=arity), key=lambda x: sum(x)):\n",
    "            # Check all possible combinations of child trees\n",
    "            for child_combination in itertools.product(*[hashes_of_size[child_length] for child_length in child_lengths]):\n",
    "                yield (new_root_operator,) + tuple(itertools.chain.from_iterable(child_combination))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.normal(loc=0, scale=5, size=(1024, space.n_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2204/10000 [00:18<01:59, 65.42it/s, Rules found: 120] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m combination \u001b[38;5;129;01min\u001b[39;00m expression_generator(hashes_of_size, non_leaf_nodes):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, rule \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(rules):\n\u001b[0;32m---> 34\u001b[0m         rules[i] \u001b[38;5;241m=\u001b[39m (rule[\u001b[38;5;241m0\u001b[39m], simplify(rule[\u001b[38;5;241m1\u001b[39m], rules))\n\u001b[1;32m     36\u001b[0m     simplified_skeleton \u001b[38;5;241m=\u001b[39m simplify(\u001b[38;5;28mlist\u001b[39m(combination), rules)\n\u001b[1;32m     37\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(simplified_skeleton)\n",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m, in \u001b[0;36msimplify\u001b[0;34m(expression, rules)\u001b[0m\n\u001b[1;32m      3\u001b[0m     expression \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(expression)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pattern, replacement \u001b[38;5;129;01min\u001b[39;00m rules:\n\u001b[0;32m----> 5\u001b[0m     expression \u001b[38;5;241m=\u001b[39m apply_rule(expression, pattern, replacement)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m expression\n",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m, in \u001b[0;36mapply_rule\u001b[0;34m(X, A, B)\u001b[0m\n\u001b[1;32m      2\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(X):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Check if sublist A is found at current position\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(A) \u001b[38;5;129;01mand\u001b[39;00m X[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(A)] \u001b[38;5;241m==\u001b[39m A:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;66;03m# Add replacement sublist B\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         result\u001b[38;5;241m.\u001b[39mextend(B)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "size = 10_000\n",
    "rules = [(['-', t, t], ['0']) for t in space.variables] + [(['/', t, t], ['1']) for t in space.variables] + [(['*', t, '1'], [t]) for t in space.variables]\n",
    "\n",
    "hashes_of_size = defaultdict(list)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "    # Create all leaf nodes\n",
    "    for leaf in leaf_nodes[:size]:\n",
    "        simplified_skeleton = simplify([leaf], rules)\n",
    "        \n",
    "        executable_prefix_expression = space.operators_to_realizations(simplified_skeleton)\n",
    "        prefix_expression_with_constants, constants = num_to_constants(executable_prefix_expression)\n",
    "        code_string = space.prefix_to_infix(prefix_expression_with_constants, realization=True)\n",
    "        code = codify(code_string, space.variables + constants)\n",
    "\n",
    "        hashes_of_size[len(simplified_skeleton)].append(tuple(simplified_skeleton))\n",
    "\n",
    "    pbar = tqdm(total=size)\n",
    "    n_scanned = 0\n",
    "\n",
    "    while n_scanned < size:\n",
    "        simplified_hashes_of_size = defaultdict(list)\n",
    "        for l, hashes_list in hashes_of_size.items():\n",
    "            for h in hashes_list:\n",
    "                simplified_skeleton = simplify(h, rules)\n",
    "                simplified_hashes_of_size[len(simplified_skeleton)].append(simplified_skeleton)\n",
    "        hashes_of_size = simplified_hashes_of_size\n",
    "\n",
    "        new_hashes_of_size = defaultdict(list)\n",
    "        for combination in expression_generator(hashes_of_size, non_leaf_nodes):\n",
    "            for i, rule in enumerate(rules):\n",
    "                rules[i] = (rule[0], simplify(rule[1], rules))\n",
    "\n",
    "            simplified_skeleton = simplify(list(combination), rules)\n",
    "            h = tuple(simplified_skeleton)\n",
    "\n",
    "            executable_prefix_expression = space.operators_to_realizations(simplified_skeleton)\n",
    "            prefix_expression_with_constants, constants = num_to_constants(executable_prefix_expression)\n",
    "            code_string = space.prefix_to_infix(prefix_expression_with_constants, realization=True)\n",
    "            code = codify(code_string, space.variables + constants)\n",
    "\n",
    "            # Record the image\n",
    "            if len(constants) == 0:\n",
    "                f = space.code_to_lambda(code)\n",
    "                y = f(*X.T)\n",
    "\n",
    "                for candidate_hashes_of_size in (hashes_of_size, new_hashes_of_size):\n",
    "                    for l, candidate_hashes_list in candidate_hashes_of_size.items():\n",
    "                        # Ignore simplification candidates that do not shorten the expression\n",
    "                        if l >= len(h):\n",
    "                            continue\n",
    "\n",
    "                        for candidate_hash in candidate_hashes_list:\n",
    "                            if candidate_hash == h:\n",
    "                                continue\n",
    "                            executable_prefix_candidate_hash = space.operators_to_realizations(candidate_hash)\n",
    "                            prefix_candidate_hash_with_constants, constants_candidate_hash = num_to_constants(executable_prefix_candidate_hash)\n",
    "                            code_string_candidate_hash = space.prefix_to_infix(prefix_candidate_hash_with_constants, realization=True)\n",
    "                            code_candidate_hash = codify(code_string_candidate_hash, space.variables + constants_candidate_hash)\n",
    "\n",
    "                            # Record the image\n",
    "                            if len(constants_candidate_hash) == 0:\n",
    "                                f_candidate = space.code_to_lambda(code_candidate_hash)\n",
    "                                y_candidate = f_candidate(*X.T)\n",
    "\n",
    "                                if np.allclose(y, y_candidate, equal_nan=True):\n",
    "                                    rules.append((simplified_skeleton, list(candidate_hash)))\n",
    "\n",
    "            new_hashes_of_size[len(h)].append(h)\n",
    "\n",
    "            n_scanned += 1\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix_str(f\"Rules found: {len(rules):,}\")\n",
    "\n",
    "            if n_scanned >= size:\n",
    "                break\n",
    "\n",
    "        hashes_of_size.update(new_hashes_of_size)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "# Write the rules to a file\n",
    "with open('./rules.txt', 'w') as f:\n",
    "    for rule in rules:\n",
    "        f.write(f\"{rule[0]} -> {rule[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit, OptimizeWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exist_constants_that_fit(expression: list[str], X: np.ndarray, y_target: np.ndarray):\n",
    "    if isinstance(expression, tuple):\n",
    "        expression = list(expression)\n",
    "\n",
    "    executable_prefix_expression = space.operators_to_realizations(expression)\n",
    "    prefix_expression_with_constants, constants = num_to_constants(executable_prefix_expression)\n",
    "    code_string = space.prefix_to_infix(prefix_expression_with_constants, realization=True)\n",
    "    code = codify(code_string, space.variables + constants)\n",
    "    f = space.code_to_lambda(code)\n",
    "\n",
    "    def pred_function(X: np.ndarray, *constants: np.ndarray | None) -> float:\n",
    "        if len(constants) == 0:\n",
    "            return f(*X.T)\n",
    "        return f(*X.T, *constants)\n",
    "\n",
    "    p0 = np.random.normal(loc=0, scale=5, size=len(constants))\n",
    "\n",
    "    is_valid = np.isfinite(X).all(axis=1) & np.isfinite(y_target)\n",
    "\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=OptimizeWarning)\n",
    "            popt, _ = curve_fit(pred_function, X[is_valid], y_target[is_valid].flatten(), p0=p0)\n",
    "    except RuntimeError:\n",
    "        return False\n",
    "\n",
    "    y = f(*X.T, *popt)\n",
    "\n",
    "    return np.allclose(y_target, y, equal_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.random.normal(loc=0, scale=5, size=(1024, 128))\n",
    "X_with_constants = np.hstack((X, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:22<00:00, 24.11it/s, Rules found: 131]\n"
     ]
    }
   ],
   "source": [
    "size = 10_000\n",
    "constants_retries = 5\n",
    "rules = [(['-', t, t], ['0']) for t in space.variables] + [(['/', t, t], ['1']) for t in space.variables] + [(['*', t, '1'], [t]) for t in space.variables]\n",
    "\n",
    "hashes_of_size = defaultdict(list)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "    # Create all leaf nodes\n",
    "    for leaf in leaf_nodes[:size]:\n",
    "        simplified_skeleton = simplify([leaf], rules)\n",
    "        \n",
    "        executable_prefix_expression = space.operators_to_realizations(simplified_skeleton)\n",
    "        prefix_expression_with_constants, constants = num_to_constants(executable_prefix_expression)\n",
    "        code_string = space.prefix_to_infix(prefix_expression_with_constants, realization=True)\n",
    "        code = codify(code_string, space.variables + constants)\n",
    "\n",
    "        hashes_of_size[len(simplified_skeleton)].append(tuple(simplified_skeleton))\n",
    "\n",
    "    pbar = tqdm(total=size)\n",
    "    n_scanned = 0\n",
    "\n",
    "    while n_scanned < size:\n",
    "        simplified_hashes_of_size = defaultdict(list)\n",
    "        for l, hashes_list in hashes_of_size.items():\n",
    "            for h in hashes_list:\n",
    "                simplified_skeleton = simplify(h, rules)\n",
    "                simplified_hashes_of_size[len(simplified_skeleton)].append(simplified_skeleton)\n",
    "        hashes_of_size = simplified_hashes_of_size\n",
    "\n",
    "        new_hashes_of_size = defaultdict(list)\n",
    "        for combination in expression_generator(hashes_of_size, non_leaf_nodes):\n",
    "            for i, rule in enumerate(rules):\n",
    "                rules[i] = (rule[0], simplify(rule[1], rules))\n",
    "\n",
    "            simplified_skeleton = simplify(list(combination), rules)\n",
    "            h = tuple(simplified_skeleton)\n",
    "\n",
    "            executable_prefix_expression = space.operators_to_realizations(simplified_skeleton)\n",
    "            prefix_expression_with_constants, constants = num_to_constants(executable_prefix_expression)\n",
    "            code_string = space.prefix_to_infix(prefix_expression_with_constants, realization=True)\n",
    "            code = codify(code_string, space.variables + constants)\n",
    "            \n",
    "            f = space.code_to_lambda(code)\n",
    "\n",
    "            # Record the image\n",
    "            if len(constants) == 0:\n",
    "                y = f(*X.T)\n",
    "\n",
    "                for candidate_hashes_of_size in (hashes_of_size, new_hashes_of_size):\n",
    "                    for l, candidate_hashes_list in candidate_hashes_of_size.items():\n",
    "                        # Ignore simplification candidates that do not shorten the expression\n",
    "                        if l >= len(h):\n",
    "                            continue\n",
    "\n",
    "                        for candidate_hash in candidate_hashes_list:\n",
    "                            if candidate_hash == h:\n",
    "                                continue\n",
    "                            executable_prefix_candidate_hash = space.operators_to_realizations(candidate_hash)\n",
    "                            prefix_candidate_hash_with_constants, constants_candidate_hash = num_to_constants(executable_prefix_candidate_hash)\n",
    "                            code_string_candidate_hash = space.prefix_to_infix(prefix_candidate_hash_with_constants, realization=True)\n",
    "                            code_candidate_hash = codify(code_string_candidate_hash, space.variables + constants_candidate_hash)\n",
    "\n",
    "                            # Record the image\n",
    "                            if len(constants_candidate_hash) == 0:\n",
    "                                f_candidate = space.code_to_lambda(code_candidate_hash)\n",
    "                                y_candidate = f_candidate(*X.T)\n",
    "\n",
    "                                if np.allclose(y, y_candidate, equal_nan=True):\n",
    "                                    rules.append((simplified_skeleton, list(candidate_hash)))\n",
    "                            else:\n",
    "                                if any([exist_constants_that_fit(candidate_hash, X, y) for _ in range(constants_retries)]):\n",
    "                                    rules.append((simplified_skeleton, list(candidate_hash)))\n",
    "            else:\n",
    "                # Create an image from X and randomly sampled constants\n",
    "                # TODO: use multiple images here\n",
    "                y = f(*X_with_constants[:, :len(space.variables) + len(constants)].T)\n",
    "\n",
    "                for candidate_hashes_of_size in (hashes_of_size, new_hashes_of_size):\n",
    "                    for l, candidate_hashes_list in candidate_hashes_of_size.items():\n",
    "                        # Ignore simplification candidates that do not shorten the expression\n",
    "                        if l >= len(h):\n",
    "                            continue\n",
    "\n",
    "                        for candidate_hash in candidate_hashes_list:\n",
    "                            if candidate_hash == h:\n",
    "                                continue\n",
    "                            executable_prefix_candidate_hash = space.operators_to_realizations(candidate_hash)\n",
    "                            prefix_candidate_hash_with_constants, constants_candidate_hash = num_to_constants(executable_prefix_candidate_hash)\n",
    "                            code_string_candidate_hash = space.prefix_to_infix(prefix_candidate_hash_with_constants, realization=True)\n",
    "                            code_candidate_hash = codify(code_string_candidate_hash, space.variables + constants_candidate_hash)\n",
    "\n",
    "                            f_candidate = space.code_to_lambda(code_candidate_hash)\n",
    "\n",
    "                            # Record the image\n",
    "                            if len(constants_candidate_hash) == 0:\n",
    "                                y_candidate = f_candidate(*X.T)\n",
    "\n",
    "                                if np.allclose(y, y_candidate, equal_nan=True):\n",
    "                                    rules.append((simplified_skeleton, list(candidate_hash)))\n",
    "                            else:\n",
    "                                if any([exist_constants_that_fit(candidate_hash, X, y) for _ in range(constants_retries)]):\n",
    "                                    rules.append((simplified_skeleton, list(candidate_hash)))\n",
    "\n",
    "            new_hashes_of_size[len(h)].append(h)\n",
    "\n",
    "            n_scanned += 1\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix_str(f\"Rules found: {len(rules):,}\")\n",
    "\n",
    "            if n_scanned >= size:\n",
    "                break\n",
    "\n",
    "        hashes_of_size.update(new_hashes_of_size)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "# Write the rules to a file\n",
    "with open('./rules_constants.txt', 'w') as f:\n",
    "    for rule in rules:\n",
    "        f.write(f\"{rule[0]} -> {rule[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flash-ansr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
