{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flash_ansr.expressions import ExpressionSpace\n",
    "from flash_ansr.expressions.utils import codify, num_to_constants\n",
    "from flash_ansr import get_path\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from typing import Generator, Callable\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'v7.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_path('configs', MODEL, 'expression_space.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = ExpressionSpace.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x1', 'x2', 'x3', '<num>']\n",
      "{'neg': 1, 'abs': 1, 'inv': 1, 'pow2': 1, 'pow3': 1, 'pow4': 1, 'pow5': 1, 'pow1_2': 1, 'pow1_3': 1, 'pow1_4': 1, 'pow1_5': 1, 'sin': 1, 'cos': 1, 'tan': 1, 'asin': 1, 'acos': 1, 'atan': 1, 'exp': 1, 'log': 1, '+': 2, '-': 2, '*': 2, '/': 2}\n"
     ]
    }
   ],
   "source": [
    "leaf_nodes = space.variables + [\"<num>\"]\n",
    "non_leaf_nodes = space.operator_arity\n",
    "non_leaf_nodes = dict(sorted(non_leaf_nodes.items(), key=lambda x: x[1]))\n",
    "\n",
    "print(leaf_nodes)\n",
    "print(non_leaf_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['+', 'cos', 'x', 'sin', '*', 'pow2', 'x', 'pow2', 'x']\n"
     ]
    }
   ],
   "source": [
    "def apply_rule(X, A, B):\n",
    "    result = []\n",
    "    i = 0\n",
    "    while i < len(X):\n",
    "        # Check if sublist A is found at current position\n",
    "        if i <= len(X) - len(A) and X[i:i+len(A)] == A:\n",
    "            # Add replacement sublist B\n",
    "            result.extend(B)\n",
    "            # Skip past the matched sublist A\n",
    "            i += len(A)\n",
    "        else:\n",
    "            # Add current element and move to next\n",
    "            result.append(X[i])\n",
    "            i += 1\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "X = ['+', 'cos', 'x', 'sin', '*', '*', 'x', 'x', '*', 'x', 'x']\n",
    "A = ['*', 'x', 'x']\n",
    "B = ['pow2', 'x']\n",
    "print(apply_rule(X, A, B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify(expression: list[str], rules: set[tuple[list[str], list[str]]]):\n",
    "    if isinstance(expression, tuple):\n",
    "        expression = list(expression)\n",
    "    for pattern, replacement in rules:\n",
    "        expression = apply_rule(expression, pattern, replacement)\n",
    "    return expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['+', 'cos', 'x', 'sin', '*', 'pow2', 'x', 'pow2', 'x']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplify(['+', 'cos', 'x', 'sin', '*', '*', 'x', 'x', '*', 'x', 'x'], [(['*', 'x', 'x'], ['pow2', 'x'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', '0']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplify(['neg', '-', 'x1', 'x1'], [(['-', 'x1', 'x1'], ['0'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<num>']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplify(['<num>'], rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expression_generator(hashes_of_size: dict[int, list[tuple[str]]], non_leaf_nodes: dict[str, int]) -> Generator[tuple[str], None, None]:\n",
    "    # Append existing trees to every operator\n",
    "    for new_root_operator, arity in non_leaf_nodes.items():\n",
    "        # Start with the smallest arity-tuples of trees\n",
    "        for child_lengths in sorted(itertools.product(list(hashes_of_size.keys()), repeat=arity), key=lambda x: sum(x)):\n",
    "            # Check all possible combinations of child trees\n",
    "            for child_combination in itertools.product(*[hashes_of_size[child_length] for child_length in child_lengths]):\n",
    "                yield (new_root_operator,) + tuple(itertools.chain.from_iterable(child_combination))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.normal(loc=0, scale=5, size=(1024, space.n_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:31<?, ?it/s, Rules found: 0, Current Expression: ('neg', 'x1')]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "size = 0\n",
    "rules = []\n",
    "\n",
    "hashes_of_size = defaultdict(list)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "    # Create all leaf nodes\n",
    "    for leaf in leaf_nodes[:size]:\n",
    "        simplified_skeleton = simplify([leaf], rules)\n",
    "        \n",
    "        executable_prefix_expression = space.operators_to_realizations(simplified_skeleton)\n",
    "        prefix_expression_with_constants, constants = num_to_constants(executable_prefix_expression)\n",
    "        code_string = space.prefix_to_infix(prefix_expression_with_constants, realization=True)\n",
    "        code = codify(code_string, space.variables + constants)\n",
    "\n",
    "        hashes_of_size[len(simplified_skeleton)].append(tuple(simplified_skeleton))\n",
    "\n",
    "    pbar = tqdm(total=size)\n",
    "    n_scanned = 0\n",
    "\n",
    "    while n_scanned < size:\n",
    "        simplified_hashes_of_size = defaultdict(list)\n",
    "        for l, hashes_list in hashes_of_size.items():\n",
    "            for h in hashes_list:\n",
    "                simplified_skeleton = simplify(h, rules)\n",
    "                simplified_hashes_of_size[len(simplified_skeleton)].append(simplified_skeleton)\n",
    "        hashes_of_size = simplified_hashes_of_size\n",
    "\n",
    "        new_hashes_of_size = defaultdict(list)\n",
    "        for combination in expression_generator(hashes_of_size, non_leaf_nodes):\n",
    "            for i, rule in enumerate(rules):\n",
    "                rules[i] = (rule[0], simplify(rule[1], rules))\n",
    "\n",
    "            simplified_skeleton = simplify(list(combination), rules)\n",
    "            h = tuple(simplified_skeleton)\n",
    "\n",
    "            executable_prefix_expression = space.operators_to_realizations(simplified_skeleton)\n",
    "            prefix_expression_with_constants, constants = num_to_constants(executable_prefix_expression)\n",
    "            code_string = space.prefix_to_infix(prefix_expression_with_constants, realization=True)\n",
    "            code = codify(code_string, space.variables + constants)\n",
    "\n",
    "            # Record the image\n",
    "            if len(constants) == 0:\n",
    "                f = space.code_to_lambda(code)\n",
    "                y = f(*X.T)\n",
    "\n",
    "                for candidate_hashes_of_size in (hashes_of_size, new_hashes_of_size):\n",
    "                    for l, candidate_hashes_list in candidate_hashes_of_size.items():\n",
    "                        # Ignore simplification candidates that do not shorten the expression\n",
    "                        if l >= len(h):\n",
    "                            continue\n",
    "\n",
    "                        for candidate_hash in candidate_hashes_list:\n",
    "                            if candidate_hash == h:\n",
    "                                continue\n",
    "                            executable_prefix_candidate_hash = space.operators_to_realizations(candidate_hash)\n",
    "                            prefix_candidate_hash_with_constants, constants_candidate_hash = num_to_constants(executable_prefix_candidate_hash)\n",
    "                            code_string_candidate_hash = space.prefix_to_infix(prefix_candidate_hash_with_constants, realization=True)\n",
    "                            code_candidate_hash = codify(code_string_candidate_hash, space.variables + constants_candidate_hash)\n",
    "\n",
    "                            # Record the image\n",
    "                            if len(constants_candidate_hash) == 0:\n",
    "                                f_candidate = space.code_to_lambda(code_candidate_hash)\n",
    "                                y_candidate = f_candidate(*X.T)\n",
    "\n",
    "                                if np.allclose(y, y_candidate, equal_nan=True):\n",
    "                                    rules.append((simplified_skeleton, list(candidate_hash)))\n",
    "\n",
    "            new_hashes_of_size[len(h)].append(h)\n",
    "\n",
    "            n_scanned += 1\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix_str(f\"Rules found: {len(rules):,}\")\n",
    "\n",
    "            if n_scanned >= size:\n",
    "                break\n",
    "\n",
    "        hashes_of_size.update(new_hashes_of_size)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "# Write the rules to a file\n",
    "with open('./rules.txt', 'w') as f:\n",
    "    for rule in rules:\n",
    "        f.write(f\"{rule[0]} -> {rule[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit, OptimizeWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exist_constants_that_fit(expression: list[str], X: np.ndarray, y_target: np.ndarray):\n",
    "    if isinstance(expression, tuple):\n",
    "        expression = list(expression)\n",
    "\n",
    "    executable_prefix_expression = space.operators_to_realizations(expression)\n",
    "    prefix_expression_with_constants, constants = num_to_constants(executable_prefix_expression, convert_numbers_to_constant=False)\n",
    "    code_string = space.prefix_to_infix(prefix_expression_with_constants, realization=True)\n",
    "    code = codify(code_string, space.variables + constants)\n",
    "    f = space.code_to_lambda(code)\n",
    "\n",
    "    def pred_function(X: np.ndarray, *constants: np.ndarray | None) -> float:\n",
    "        if len(constants) == 0:\n",
    "            return f(*X.T)\n",
    "        return f(*X.T, *constants)\n",
    "\n",
    "    p0 = np.random.normal(loc=0, scale=5, size=len(constants))\n",
    "\n",
    "    is_valid = np.isfinite(X).all(axis=1) & np.isfinite(y_target)\n",
    "\n",
    "    if not np.any(is_valid):\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=OptimizeWarning)\n",
    "            popt, _ = curve_fit(pred_function, X[is_valid], y_target[is_valid].flatten(), p0=p0)\n",
    "    except RuntimeError:\n",
    "        return False\n",
    "\n",
    "    y = f(*X.T, *popt)\n",
    "    if not isinstance(y, np.ndarray):\n",
    "        y = np.full(X.shape[0], y)\n",
    "\n",
    "    return np.allclose(y_target, y, equal_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.random.normal(loc=0, scale=5, size=(1024, 128))\n",
    "X_with_constants = np.hstack((X, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_f(f, X):\n",
    "    try:\n",
    "        return f(*X.T)\n",
    "    except ZeroDivisionError:\n",
    "        return np.full(X.shape[0], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 154/1000 [00:01<00:11, 70.94it/s, Rules found: 47, Current Expression: ('-', 'x1', '0') -> ['-', 'x1', '0'] -> ...]               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('-', 'x1', 'x1')\n",
      "['<num>'] ['C_0'] ['C_0'] C_0\n",
      "['0'] ['0'] [] 0\n",
      "['nsrops.neg', '<num>'] ['nsrops.neg', 'C_0'] ['C_0'] nsrops.neg(C_0)\n",
      "['nsrops.neg', '0'] ['nsrops.neg', '0'] [] nsrops.neg(0)\n",
      "['abs', '<num>'] ['abs', 'C_0'] ['C_0'] abs(C_0)\n",
      "['abs', '0'] ['abs', '0'] [] abs(0)\n",
      "['nsrops.pow2', '0'] ['nsrops.pow2', '0'] [] nsrops.pow2(0)\n",
      "['nsrops.pow3', '0'] ['nsrops.pow3', '0'] [] nsrops.pow3(0)\n",
      "['nsrops.pow4', '0'] ['nsrops.pow4', '0'] [] nsrops.pow4(0)\n",
      "['nsrops.pow5', '0'] ['nsrops.pow5', '0'] [] nsrops.pow5(0)\n",
      "['nsrops.pow1_2', '0'] ['nsrops.pow1_2', '0'] [] nsrops.pow1_2(0)\n",
      "['nsrops.pow1_3', '0'] ['nsrops.pow1_3', '0'] [] nsrops.pow1_3(0)\n",
      "['nsrops.pow1_4', '0'] ['nsrops.pow1_4', '0'] [] nsrops.pow1_4(0)\n",
      "['nsrops.pow1_5', '0'] ['nsrops.pow1_5', '0'] [] nsrops.pow1_5(0)\n",
      "['numpy.sin', '<num>'] ['numpy.sin', 'C_0'] ['C_0'] numpy.sin(C_0)\n",
      "['numpy.sin', '0'] ['numpy.sin', '0'] [] numpy.sin(0)\n",
      "['numpy.cos', '<num>'] ['numpy.cos', 'C_0'] ['C_0'] numpy.cos(C_0)\n",
      "['numpy.tan', '<num>'] ['numpy.tan', 'C_0'] ['C_0'] numpy.tan(C_0)\n",
      "['numpy.tan', '0'] ['numpy.tan', '0'] [] numpy.tan(0)\n",
      "['numpy.arcsin', '<num>'] ['numpy.arcsin', 'C_0'] ['C_0'] numpy.arcsin(C_0)\n",
      "['numpy.arcsin', '0'] ['numpy.arcsin', '0'] [] numpy.arcsin(0)\n",
      "['numpy.arccos', '1'] ['numpy.arccos', '1'] [] numpy.arccos(1)\n",
      "['numpy.arctan', '<num>'] ['numpy.arctan', 'C_0'] ['C_0'] numpy.arctan(C_0)\n",
      "['numpy.arctan', '0'] ['numpy.arctan', '0'] [] numpy.arctan(0)\n",
      "['numpy.log', '<num>'] ['numpy.log', 'C_0'] ['C_0'] numpy.log(C_0)\n",
      "['numpy.log', '1'] ['numpy.log', '1'] [] numpy.log(1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:19<00:00,  7.19it/s, Rules found: 169, Current Expression: ('inv', '-', 'x3', 'x1') -> ['inv', '-', 'x3', 'x1'] -> ...]           \n"
     ]
    }
   ],
   "source": [
    "size = 10_000\n",
    "constants_retries = 5\n",
    "rules = [(['-', t, t], ['0']) for t in space.variables] + [(['/', t, t], ['1']) for t in space.variables] + [(['*', t, '1'], [t]) for t in space.variables]\n",
    "\n",
    "hashes_of_size = defaultdict(list)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "    # Create all leaf nodes\n",
    "    for leaf in leaf_nodes[:size]:\n",
    "        simplified_skeleton = simplify([leaf], rules)\n",
    "        \n",
    "        executable_prefix_expression = space.operators_to_realizations(simplified_skeleton)\n",
    "        prefix_expression_with_constants, constants = num_to_constants(executable_prefix_expression)\n",
    "        code_string = space.prefix_to_infix(prefix_expression_with_constants, realization=True)\n",
    "        code = codify(code_string, space.variables + constants)\n",
    "\n",
    "        hashes_of_size[len(simplified_skeleton)].append(tuple(simplified_skeleton))\n",
    "\n",
    "    pbar = tqdm(total=size)\n",
    "    n_scanned = 0\n",
    "\n",
    "    while n_scanned < size:\n",
    "        simplified_hashes_of_size = defaultdict(list)\n",
    "        for l, hashes_list in hashes_of_size.items():\n",
    "            for h in hashes_list:\n",
    "                simplified_skeleton = simplify(h, rules)\n",
    "                simplified_hashes_of_size[len(simplified_skeleton)].append(simplified_skeleton)\n",
    "        hashes_of_size = simplified_hashes_of_size\n",
    "\n",
    "        new_hashes_of_size = defaultdict(list)\n",
    "        for combination in expression_generator(hashes_of_size, non_leaf_nodes):\n",
    "            pbar.set_postfix_str(f\"Rules found: {len(rules):,}, Current Expression: {combination}\")\n",
    "            for i, rule in enumerate(rules):\n",
    "                rules[i] = (rule[0], simplify(rule[1], rules))\n",
    "\n",
    "            simplified_skeleton = simplify(list(combination), rules)\n",
    "            h = tuple(simplified_skeleton)\n",
    "\n",
    "            executable_prefix_expression = space.operators_to_realizations(simplified_skeleton)\n",
    "            prefix_expression_with_constants, constants = num_to_constants(executable_prefix_expression)\n",
    "            code_string = space.prefix_to_infix(prefix_expression_with_constants, realization=True)\n",
    "            code = codify(code_string, space.variables + constants)\n",
    "            \n",
    "            f = space.code_to_lambda(code)\n",
    "\n",
    "            # Record the image\n",
    "            if len(constants) == 0:\n",
    "                y = f(*X.T)\n",
    "\n",
    "                for candidate_hashes_of_size in (hashes_of_size, new_hashes_of_size):\n",
    "                    for l, candidate_hashes_list in candidate_hashes_of_size.items():\n",
    "                        # Ignore simplification candidates that do not shorten the expression\n",
    "                        if l >= len(h):\n",
    "                            continue\n",
    "\n",
    "                        for candidate_hash in candidate_hashes_list:\n",
    "                            if candidate_hash == h:\n",
    "                                continue\n",
    "                            executable_prefix_candidate_hash = space.operators_to_realizations(candidate_hash)\n",
    "                            prefix_candidate_hash_with_constants, constants_candidate_hash = num_to_constants(executable_prefix_candidate_hash)\n",
    "                            code_string_candidate_hash = space.prefix_to_infix(prefix_candidate_hash_with_constants, realization=True)\n",
    "                            code_candidate_hash = codify(code_string_candidate_hash, space.variables + constants_candidate_hash)\n",
    "\n",
    "                            # Record the image\n",
    "                            if len(constants_candidate_hash) == 0:\n",
    "                                f_candidate = space.code_to_lambda(code_candidate_hash)\n",
    "                                y_candidate = f_candidate(*X.T)\n",
    "\n",
    "                                if np.allclose(y, y_candidate, equal_nan=True):\n",
    "                                    rules.append((simplified_skeleton, list(candidate_hash)))\n",
    "                            else:\n",
    "                                if any([exist_constants_that_fit(candidate_hash, X, y) for _ in range(constants_retries)]):\n",
    "                                    rules.append((simplified_skeleton, list(candidate_hash)))\n",
    "            else:\n",
    "                # Create an image from X and randomly sampled constants\n",
    "                y = f(*X_with_constants[:, :len(space.variables) + len(constants)].T)\n",
    "\n",
    "                for candidate_hashes_of_size in (hashes_of_size, new_hashes_of_size):\n",
    "                    for l, candidate_hashes_list in candidate_hashes_of_size.items():\n",
    "                        # Ignore simplification candidates that do not shorten the expression\n",
    "                        if l >= len(h):\n",
    "                            continue\n",
    "\n",
    "                        for candidate_hash in candidate_hashes_list:\n",
    "                            if candidate_hash == h:\n",
    "                                continue\n",
    "                            executable_prefix_candidate_hash = space.operators_to_realizations(candidate_hash)\n",
    "                            prefix_candidate_hash_with_constants, constants_candidate_hash = num_to_constants(executable_prefix_candidate_hash)\n",
    "                            code_string_candidate_hash = space.prefix_to_infix(prefix_candidate_hash_with_constants, realization=True)\n",
    "                            code_candidate_hash = codify(code_string_candidate_hash, space.variables + constants_candidate_hash)\n",
    "\n",
    "                            f_candidate = space.code_to_lambda(code_candidate_hash)\n",
    "\n",
    "                            # Record the image\n",
    "                            if len(constants_candidate_hash) == 0:\n",
    "                                y_candidate = f_candidate(*X.T)\n",
    "\n",
    "                                if np.allclose(y, y_candidate, equal_nan=True):\n",
    "                                    rules.append((simplified_skeleton, list(candidate_hash)))\n",
    "                            else:\n",
    "                                if any([exist_constants_that_fit(candidate_hash, X, y) for _ in range(constants_retries)]):\n",
    "                                    rules.append((simplified_skeleton, list(candidate_hash)))\n",
    "\n",
    "            new_hashes_of_size[len(h)].append(h)\n",
    "\n",
    "            n_scanned += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "            if n_scanned >= size:\n",
    "                break\n",
    "\n",
    "        hashes_of_size.update(new_hashes_of_size)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "# Write the rules to a file\n",
    "with open('./rules_constants.txt', 'w') as f:\n",
    "    for rule in rules:\n",
    "        f.write(f\"{rule[0]} -> {rule[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 528/1000 [00:28<01:29,  5.29it/s, Rules found: 148, Current Expression: ('inv', '+', 'x3', '<num>')]   "
     ]
    }
   ],
   "source": [
    "size = 1_000\n",
    "constants_retries = 5\n",
    "rules = []\n",
    "\n",
    "hashes_of_size = defaultdict(list)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "    # Create all leaf nodes\n",
    "    for leaf in leaf_nodes[:size]:\n",
    "        simplified_skeleton = simplify([leaf], rules)\n",
    "        \n",
    "        executable_prefix_expression = space.operators_to_realizations(simplified_skeleton)\n",
    "        prefix_expression_with_constants, constants = num_to_constants(executable_prefix_expression)\n",
    "        code_string = space.prefix_to_infix(prefix_expression_with_constants, realization=True)\n",
    "        code = codify(code_string, space.variables + constants)\n",
    "\n",
    "        hashes_of_size[len(simplified_skeleton)].append(tuple(simplified_skeleton))\n",
    "\n",
    "    pbar = tqdm(total=size)\n",
    "    n_scanned = 0\n",
    "\n",
    "    while n_scanned < size:\n",
    "        simplified_hashes_of_size = defaultdict(list)\n",
    "        for l, hashes_list in hashes_of_size.items():\n",
    "            for h in hashes_list:\n",
    "                simplified_skeleton = simplify(h, rules)\n",
    "                simplified_hashes_of_size[len(simplified_skeleton)].append(simplified_skeleton)\n",
    "        hashes_of_size = simplified_hashes_of_size\n",
    "\n",
    "        new_hashes_of_size = defaultdict(list)\n",
    "        for combination in expression_generator(hashes_of_size, non_leaf_nodes):\n",
    "            for i, rule in enumerate(rules):\n",
    "                rules[i] = (rule[0], simplify(rule[1], rules))\n",
    "\n",
    "            simplified_skeleton = simplify(list(combination), rules)\n",
    "            h = tuple(simplified_skeleton)\n",
    "\n",
    "            pbar.set_postfix_str(f\"Rules found: {len(rules):,}, Current Expression: {combination} -> {simplified_skeleton} -> ...\")\n",
    "\n",
    "            executable_prefix_expression = space.operators_to_realizations(simplified_skeleton)\n",
    "            prefix_expression_with_constants, constants = num_to_constants(executable_prefix_expression)\n",
    "            code_string = space.prefix_to_infix(prefix_expression_with_constants, realization=True)\n",
    "            code = codify(code_string, space.variables + constants)\n",
    "            \n",
    "            f = space.code_to_lambda(code)\n",
    "\n",
    "            # Record the image\n",
    "            if len(constants) == 0:\n",
    "                y = f(*X.T)\n",
    "\n",
    "                for candidate_hashes_of_size in (hashes_of_size, new_hashes_of_size):\n",
    "                    for l, candidate_hashes_list in candidate_hashes_of_size.items():\n",
    "                        # Ignore simplification candidates that do not shorten the expression\n",
    "                        if l >= len(h):\n",
    "                            continue\n",
    "\n",
    "                        for candidate_hash in candidate_hashes_list:\n",
    "                            if candidate_hash == h:\n",
    "                                continue\n",
    "                            executable_prefix_candidate_hash = space.operators_to_realizations(candidate_hash)\n",
    "                            prefix_candidate_hash_with_constants, constants_candidate_hash = num_to_constants(executable_prefix_candidate_hash)\n",
    "                            code_string_candidate_hash = space.prefix_to_infix(prefix_candidate_hash_with_constants, realization=True)\n",
    "                            code_candidate_hash = codify(code_string_candidate_hash, space.variables + constants_candidate_hash)\n",
    "\n",
    "                            # Record the image\n",
    "                            if len(constants_candidate_hash) == 0:\n",
    "                                f_candidate = space.code_to_lambda(code_candidate_hash)\n",
    "                                y_candidate = f_candidate(*X.T)\n",
    "\n",
    "                                if np.allclose(y, y_candidate, equal_nan=True):\n",
    "                                    rules.append((simplified_skeleton, list(candidate_hash)))\n",
    "                            else:\n",
    "                                if any([exist_constants_that_fit(candidate_hash, X, y) for _ in range(constants_retries)]):\n",
    "                                    rules.append((simplified_skeleton, list(candidate_hash)))\n",
    "            else:\n",
    "                # Create an image from X and randomly sampled constants\n",
    "                y = f(*X_with_constants[:, :len(space.variables) + len(constants)].T)\n",
    "\n",
    "                for candidate_hashes_of_size in (hashes_of_size, new_hashes_of_size):\n",
    "                    for l, candidate_hashes_list in candidate_hashes_of_size.items():\n",
    "                        # Ignore simplification candidates that do not shorten the expression\n",
    "                        if l >= len(h):\n",
    "                            continue\n",
    "\n",
    "                        for candidate_hash in candidate_hashes_list:\n",
    "                            if candidate_hash == h:\n",
    "                                continue\n",
    "                            executable_prefix_candidate_hash = space.operators_to_realizations(candidate_hash)\n",
    "                            prefix_candidate_hash_with_constants, constants_candidate_hash = num_to_constants(executable_prefix_candidate_hash)\n",
    "                            code_string_candidate_hash = space.prefix_to_infix(prefix_candidate_hash_with_constants, realization=True)\n",
    "                            code_candidate_hash = codify(code_string_candidate_hash, space.variables + constants_candidate_hash)\n",
    "\n",
    "                            f_candidate = space.code_to_lambda(code_candidate_hash)\n",
    "\n",
    "                            # Record the image\n",
    "                            if len(constants_candidate_hash) == 0:\n",
    "                                y_candidate = f_candidate(*X.T)\n",
    "\n",
    "                                if np.allclose(y, y_candidate, equal_nan=True):\n",
    "                                    rules.append((simplified_skeleton, list(candidate_hash)))\n",
    "                            else:\n",
    "                                if any([exist_constants_that_fit(candidate_hash, X, y) for _ in range(constants_retries)]):\n",
    "                                    rules.append((simplified_skeleton, list(candidate_hash)))\n",
    "\n",
    "            new_hashes_of_size[len(h)].append(h)\n",
    "\n",
    "            n_scanned += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "            if n_scanned >= size:\n",
    "                break\n",
    "\n",
    "        hashes_of_size.update(new_hashes_of_size)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "# Write the rules to a file\n",
    "with open('./rules_constants.txt', 'w') as f:\n",
    "    for rule in rules:\n",
    "        f.write(f\"{rule[0]} -> {rule[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 154/1000 [00:01<00:11, 70.94it/s, Rules found: 47, Current Expression: ('-', 'x1', '0') -> ['-', 'x1', '0'] -> ...]               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('-', 'x1', 'x1')\n",
      "['<num>'] ['C_0'] ['C_0'] C_0\n",
      "['0'] ['0'] [] 0\n",
      "['nsrops.neg', '<num>'] ['nsrops.neg', 'C_0'] ['C_0'] nsrops.neg(C_0)\n",
      "['nsrops.neg', '0'] ['nsrops.neg', '0'] [] nsrops.neg(0)\n",
      "['abs', '<num>'] ['abs', 'C_0'] ['C_0'] abs(C_0)\n",
      "['abs', '0'] ['abs', '0'] [] abs(0)\n",
      "['nsrops.pow2', '0'] ['nsrops.pow2', '0'] [] nsrops.pow2(0)\n",
      "['nsrops.pow3', '0'] ['nsrops.pow3', '0'] [] nsrops.pow3(0)\n",
      "['nsrops.pow4', '0'] ['nsrops.pow4', '0'] [] nsrops.pow4(0)\n",
      "['nsrops.pow5', '0'] ['nsrops.pow5', '0'] [] nsrops.pow5(0)\n",
      "['nsrops.pow1_2', '0'] ['nsrops.pow1_2', '0'] [] nsrops.pow1_2(0)\n",
      "['nsrops.pow1_3', '0'] ['nsrops.pow1_3', '0'] [] nsrops.pow1_3(0)\n",
      "['nsrops.pow1_4', '0'] ['nsrops.pow1_4', '0'] [] nsrops.pow1_4(0)\n",
      "['nsrops.pow1_5', '0'] ['nsrops.pow1_5', '0'] [] nsrops.pow1_5(0)\n",
      "['numpy.sin', '<num>'] ['numpy.sin', 'C_0'] ['C_0'] numpy.sin(C_0)\n",
      "['numpy.sin', '0'] ['numpy.sin', '0'] [] numpy.sin(0)\n",
      "['numpy.cos', '<num>'] ['numpy.cos', 'C_0'] ['C_0'] numpy.cos(C_0)\n",
      "['numpy.tan', '<num>'] ['numpy.tan', 'C_0'] ['C_0'] numpy.tan(C_0)\n",
      "['numpy.tan', '0'] ['numpy.tan', '0'] [] numpy.tan(0)\n",
      "['numpy.arcsin', '<num>'] ['numpy.arcsin', 'C_0'] ['C_0'] numpy.arcsin(C_0)\n",
      "['numpy.arcsin', '0'] ['numpy.arcsin', '0'] [] numpy.arcsin(0)\n",
      "['numpy.arccos', '1'] ['numpy.arccos', '1'] [] numpy.arccos(1)\n",
      "['numpy.arctan', '<num>'] ['numpy.arctan', 'C_0'] ['C_0'] numpy.arctan(C_0)\n",
      "['numpy.arctan', '0'] ['numpy.arctan', '0'] [] numpy.arctan(0)\n",
      "['numpy.log', '<num>'] ['numpy.log', 'C_0'] ['C_0'] numpy.log(C_0)\n",
      "['numpy.log', '1'] ['numpy.log', '1'] [] numpy.log(1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:19<00:00,  7.19it/s, Rules found: 169, Current Expression: ('inv', '-', 'x3', 'x1') -> ['inv', '-', 'x3', 'x1'] -> ...]           \n"
     ]
    }
   ],
   "source": [
    "size = 1_000\n",
    "constants_retries = 5\n",
    "rules = []\n",
    "\n",
    "hashes_of_size = defaultdict(list)\n",
    "\n",
    "leaf_nodes = space.variables + [\"<num>\"] + ['0', '1']\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "    # Create all leaf nodes\n",
    "    for leaf in leaf_nodes[:size]:\n",
    "        simplified_skeleton = simplify([leaf], rules)\n",
    "        \n",
    "        executable_prefix_expression = space.operators_to_realizations(simplified_skeleton)\n",
    "        prefix_expression_with_constants, constants = num_to_constants(executable_prefix_expression, convert_numbers_to_constant=False)\n",
    "        code_string = space.prefix_to_infix(prefix_expression_with_constants, realization=True)\n",
    "        code = codify(code_string, space.variables + constants)\n",
    "\n",
    "        hashes_of_size[len(simplified_skeleton)].append(tuple(simplified_skeleton))\n",
    "\n",
    "    pbar = tqdm(total=size)\n",
    "    n_scanned = 0\n",
    "\n",
    "    while n_scanned < size:\n",
    "        simplified_hashes_of_size = defaultdict(list)\n",
    "        for l, hashes_list in hashes_of_size.items():\n",
    "            for h in hashes_list:\n",
    "                simplified_skeleton = simplify(h, rules)\n",
    "                simplified_hashes_of_size[len(simplified_skeleton)].append(simplified_skeleton)\n",
    "        hashes_of_size = simplified_hashes_of_size\n",
    "\n",
    "        new_hashes_of_size = defaultdict(list)\n",
    "        for combination in expression_generator(hashes_of_size, non_leaf_nodes):\n",
    "            if combination == ('-', 'x1', 'x1'):\n",
    "                print(combination)\n",
    "            for i, rule in enumerate(rules):\n",
    "                rules[i] = (rule[0], simplify(rule[1], rules))\n",
    "\n",
    "            simplified_skeleton = simplify(list(combination), rules)\n",
    "            h = tuple(simplified_skeleton)\n",
    "\n",
    "            pbar.set_postfix_str(f\"Rules found: {len(rules):,}, Current Expression: {combination} -> {simplified_skeleton} -> ...\")\n",
    "\n",
    "            executable_prefix_expression = space.operators_to_realizations(simplified_skeleton)\n",
    "            prefix_expression_with_constants, constants = num_to_constants(executable_prefix_expression, convert_numbers_to_constant=False)\n",
    "            code_string = space.prefix_to_infix(prefix_expression_with_constants, realization=True)\n",
    "            code = codify(code_string, space.variables + constants)\n",
    "            \n",
    "            f = space.code_to_lambda(code)\n",
    "\n",
    "            # Record the image\n",
    "            if len(constants) == 0:\n",
    "                y = safe_f(f, X)\n",
    "                if not isinstance(y, np.ndarray):\n",
    "                    y = np.full(X.shape[0], y)\n",
    "\n",
    "                new_rule_candidates = []\n",
    "                for candidate_hashes_of_size in (hashes_of_size, new_hashes_of_size):\n",
    "                    for l, candidate_hashes_list in candidate_hashes_of_size.items():\n",
    "                        # Ignore simplification candidates that do not shorten the expression\n",
    "                        if l >= len(h):\n",
    "                            continue\n",
    "\n",
    "                        for candidate_hash in candidate_hashes_list:\n",
    "                            if candidate_hash == h:\n",
    "                                continue\n",
    "                            executable_prefix_candidate_hash = space.operators_to_realizations(candidate_hash)\n",
    "                            prefix_candidate_hash_with_constants, constants_candidate_hash = num_to_constants(executable_prefix_candidate_hash, convert_numbers_to_constant=False)\n",
    "                            code_string_candidate_hash = space.prefix_to_infix(prefix_candidate_hash_with_constants, realization=True)\n",
    "                            code_candidate_hash = codify(code_string_candidate_hash, space.variables + constants_candidate_hash)\n",
    "\n",
    "                            # print(prefix_candidate_hash_with_constants, constants_candidate_hash, code_string_candidate_hash)\n",
    "                            \n",
    "\n",
    "                            # Record the image\n",
    "                            if len(constants_candidate_hash) == 0:\n",
    "                                f_candidate = space.code_to_lambda(code_candidate_hash)\n",
    "                                y_candidate = safe_f(f_candidate, X)\n",
    "                                if not isinstance(y_candidate, np.ndarray):\n",
    "                                    y_candidate = np.full(X.shape[0], y_candidate)\n",
    "\n",
    "                                if np.allclose(y, y_candidate, equal_nan=True):\n",
    "                                    \n",
    "                                    if combination == ('-', 'x1', 'x1'):\n",
    "                                        print(executable_prefix_candidate_hash, prefix_candidate_hash_with_constants, constants_candidate_hash, code_string_candidate_hash)\n",
    "                                    new_rule_candidates.append((simplified_skeleton, list(candidate_hash)))\n",
    "                            else:\n",
    "                                if any([exist_constants_that_fit(candidate_hash, X, y) for _ in range(constants_retries)]):\n",
    "                                    if combination == ('-', 'x1', 'x1'):\n",
    "                                        print(executable_prefix_candidate_hash, prefix_candidate_hash_with_constants, constants_candidate_hash, code_string_candidate_hash)\n",
    "                                    new_rule_candidates.append((simplified_skeleton, list(candidate_hash)))\n",
    "                        \n",
    "                # Find the shortest rule\n",
    "                if len(new_rule_candidates) > 0:\n",
    "                    new_rule_candidates = sorted(new_rule_candidates, key=lambda x: len(x[1]))\n",
    "                    rules.append(new_rule_candidates[0])\n",
    "\n",
    "            else:\n",
    "                # Create an image from X and randomly sampled constants\n",
    "                y = f(*X_with_constants[:, :len(space.variables) + len(constants)].T)\n",
    "\n",
    "                new_rule_candidates = []\n",
    "                for candidate_hashes_of_size in (hashes_of_size, new_hashes_of_size):\n",
    "                    for l, candidate_hashes_list in candidate_hashes_of_size.items():\n",
    "                        # Ignore simplification candidates that do not shorten the expression\n",
    "                        if l >= len(h):\n",
    "                            continue\n",
    "\n",
    "                        for candidate_hash in candidate_hashes_list:\n",
    "                            if candidate_hash == h:\n",
    "                                continue\n",
    "                            executable_prefix_candidate_hash = space.operators_to_realizations(candidate_hash)\n",
    "                            prefix_candidate_hash_with_constants, constants_candidate_hash = num_to_constants(executable_prefix_candidate_hash, convert_numbers_to_constant=False)\n",
    "                            code_string_candidate_hash = space.prefix_to_infix(prefix_candidate_hash_with_constants, realization=True)\n",
    "                            code_candidate_hash = codify(code_string_candidate_hash, space.variables + constants_candidate_hash)\n",
    "\n",
    "                            f_candidate = space.code_to_lambda(code_candidate_hash)\n",
    "                            \n",
    "                            # Record the image\n",
    "                            if len(constants_candidate_hash) == 0:\n",
    "                                y_candidate = safe_f(f_candidate, X)\n",
    "                                if not isinstance(y_candidate, np.ndarray):\n",
    "                                    y_candidate = np.full(X.shape[0], y_candidate)\n",
    "\n",
    "                                if np.allclose(y, y_candidate, equal_nan=True):\n",
    "                                    new_rule_candidates.append((simplified_skeleton, list(candidate_hash)))\n",
    "                            else:\n",
    "                                if any([exist_constants_that_fit(candidate_hash, X, y) for _ in range(constants_retries)]):\n",
    "                                    new_rule_candidates.append((simplified_skeleton, list(candidate_hash)))\n",
    "\n",
    "                # Find the shortest rule\n",
    "                if len(new_rule_candidates) > 0:\n",
    "                    new_rule_candidates = sorted(new_rule_candidates, key=lambda x: len(x[1]))\n",
    "                    rules.append(new_rule_candidates[0])\n",
    "\n",
    "            new_hashes_of_size[len(h)].append(h)\n",
    "\n",
    "            n_scanned += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "            if n_scanned >= size:\n",
    "                break\n",
    "\n",
    "        hashes_of_size.update(new_hashes_of_size)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "# Write the rules to a file\n",
    "with open('./rules_constants.txt', 'w') as f:\n",
    "    for rule in rules:\n",
    "        f.write(f\"{rule[0]} -> {rule[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 250/1000 [00:23<01:09, 10.84it/s, Rules found: 90, Current Expression: ('/', '0', '0') -> ['/', '0', '0'] -> ...]\n"
     ]
    }
   ],
   "source": [
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./rules_constants.json', 'w') as f:\n",
    "    json.dump(rules, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flash-ansr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
