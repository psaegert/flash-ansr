{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from flash_ansr import FlashANSRDataset, get_path\n",
    "from flash_ansr.models.encoders.pre_encoder import PreEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling Skeletons: 100%|██████████| 42/42 [00:00<00:00, 33631.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# dataset = FlashANSRDataset.from_config(get_path('configs', 'v6.0', 'dataset_val.yaml'))\n",
    "dataset = FlashANSRDataset.from_config(get_path('data', 'ansr-data', 'test_set', 'feynman', 'dataset.yaml'))\n",
    "\n",
    "pre_encoder = PreEncoder(input_size=4, mode='ieee-754')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data:  88%|████████▊ | 88475/100000 [01:59<00:15, 739.14it/s, reject_rate=0.26%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_tensor_noisy.std()=tensor(nan)\n",
      "y_tensor.std()=tensor(7.8490e+37)\n",
      "r.min()=tensor(-1.6074)\n",
      "r.max()=tensor(2.7395)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape mismatch: value tensor of shape [16, 4, 16] cannot be broadcast to indexing result of shape [1, 16]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m     x_tensor \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpad(x_tensor, (\u001b[38;5;241m0\u001b[39m, pad_length, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     24\u001b[0m data_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x_tensor, y_tensor_noisy], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m data_tensor_pre_encoded \u001b[38;5;241m=\u001b[39m pre_encoder(data_tensor)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39misfinite(data_tensor_pre_encoded\u001b[38;5;241m.\u001b[39mnumpy())):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_tensor_pre_encoded\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/flash-ansr/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/flash-ansr/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Projects/flash-ansr/src/flash_ansr/models/encoders/pre_encoder.py:126\u001b[0m, in \u001b[0;36mPreEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mieee-754\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 126\u001b[0m         x_bit \u001b[38;5;241m=\u001b[39m float2bit(x)\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (x_bit\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mx_bit\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_size) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    129\u001b[0m     x_isnan \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39misnan(x)\n",
      "File \u001b[0;32m~/Projects/flash-ansr/src/flash_ansr/models/encoders/pre_encoder.py:70\u001b[0m, in \u001b[0;36mfloat2bit\u001b[0;34m(f, num_e_bits, num_m_bits, bias, dtype)\u001b[0m\n\u001b[1;32m     68\u001b[0m     neg_inf_pattern[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m num_e_bits] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# Mantissa is all zeros\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     result[is_neg_inf] \u001b[38;5;241m=\u001b[39m neg_inf_pattern\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mtype(dtype)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape mismatch: value tensor of shape [16, 4, 16] cannot be broadcast to indexing result of shape [1, 16]"
     ]
    }
   ],
   "source": [
    "for single_element_batch in dataset.iterate(size=100000, n_support=16, verbose=True):\n",
    "    input_ids, x_tensor, y_tensor, labels, constants = FlashANSRDataset.collate_batch(single_element_batch, device='cpu')\n",
    "\n",
    "    x_tensor = x_tensor.unsqueeze(0)\n",
    "    y_tensor = y_tensor.unsqueeze(0)\n",
    "\n",
    "    if not np.isfinite(y_tensor.std().numpy()):\n",
    "        print(f\"{y_tensor.std()=}\")\n",
    "\n",
    "    r = torch.randn_like(y_tensor)\n",
    "    y_tensor_noisy = y_tensor + (y_tensor.std() * r)\n",
    "\n",
    "    if not np.all(np.isfinite(y_tensor_noisy.numpy())):\n",
    "        print(f\"{y_tensor_noisy.std()=}\")\n",
    "        print(f\"{y_tensor.std()=}\")\n",
    "        print(f\"{r.min()=}\")\n",
    "        print(f\"{r.max()=}\")\n",
    "\n",
    "    # Pad the x_tensor with zeros to match the expected maximum input dimension of the set transformer\n",
    "    pad_length = 4 - x_tensor.shape[-1] - y_tensor_noisy.shape[-1]\n",
    "    if pad_length > 0:\n",
    "        x_tensor = nn.functional.pad(x_tensor, (0, pad_length, 0, 0, 0, 0), value=0)\n",
    "\n",
    "    data_tensor = torch.cat([x_tensor, y_tensor_noisy], dim=-1)\n",
    "\n",
    "    data_tensor_pre_encoded = pre_encoder(data_tensor)\n",
    "\n",
    "    if not np.all(np.isfinite(data_tensor_pre_encoded.numpy())):\n",
    "        print(f\"{data_tensor_pre_encoded.std()=}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flash-ansr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
